{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#from sklearn.preprocessing import Imputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from collections import Counter\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful user defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function gives the percentage of null values in every column if null values exists \n",
    "# and also returns a list of columns which has null values\n",
    "\n",
    "def null_value_check(train):\n",
    "    missing = []\n",
    "\n",
    "    for columns in train.columns:\n",
    "        missing_count = train[train[columns] == -1][columns].count()\n",
    "        if missing_count > 0:\n",
    "            missing.append(columns)\n",
    "            missings_perc = missing_count*100/train.shape[0]\n",
    "\n",
    "            print('Variable %s has %i missing with %f percentage'%(columns, missing_count, missings_perc))\n",
    "\n",
    "    print('\\nIn total, there are {} variables with missing values'.format(len(missing)))\n",
    "    return missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function gives the number of outliers in the columns \n",
    "# and also returns the columns with outliers\n",
    "\n",
    "def detect_outlier(df):\n",
    "    features = df.columns\n",
    "    outliers  = []\n",
    "    for i, feature in enumerate(features):\n",
    "        if df[feature].dtype == 'float64':\n",
    "            # Calculate Q1 (25th percentile of the data) for the given feature\n",
    "            Q1 = np.percentile(df[feature], 25)\n",
    "            # Calculate Q3 (75th percentile of the data) for the given feature\n",
    "            Q3 = np.percentile(df[feature], 75)\n",
    "            # Use the interquartile range to calculate an outlier step\n",
    "            step = 1.5 * (Q3 - Q1)\n",
    "            feature_outliers = df[~((df[feature] >= Q1 - step) & (df[feature] <= Q3 + step))]\n",
    "            outliers.extend(list(feature_outliers.index.values))\n",
    "            print('Feature: {}, outliers: {}\\n'.format(feature, len(feature_outliers.index)))\n",
    "    \n",
    "    multi_feature_outliers = (Counter(outliers) - Counter(set(outliers))).keys()\n",
    "    return multi_feature_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to handle imbalanced dataset. It upsamples the minority class and downsamples the majority classz\n",
    "\n",
    "def up_and_down_sampling(df_train_temp,minority_class_percent):\n",
    "    #Downsampling\n",
    "    \n",
    "    df_majority = df_train_temp[df_train_temp.target==0]\n",
    "    df_minority = df_train_temp[df_train_temp.target==1]\n",
    "    df_rows = df_train_temp.shape[0]\n",
    "    n_samples=int(df_rows*((100 - minority_class_percent)/100))\n",
    "    # Downsample majority class\n",
    "    df_majority_undersampled = resample(df_majority, \n",
    "                                     replace=True,     # sample with replacement\n",
    "                                     n_samples=n_samples,  # number of samples we want for majority variable\n",
    "                                     random_state=123) # reproducible results\n",
    "\n",
    "    # Combine minority class with Downsampled df\n",
    "    df_undersampled = pd.concat([df_majority_undersampled, df_minority])\n",
    "\n",
    "    # Display new class counts\n",
    "    print(\"Target value counts after downsampling: \\n\" , df_undersampled.target.value_counts())\n",
    "    \n",
    "\n",
    "    #Upsampling\n",
    "\n",
    "    df_majority = df_undersampled[df_undersampled.target==0]\n",
    "    df_rows = df_train_temp.shape[0]\n",
    "    n_samples=int(df_rows*(minority_class_percent/100))\n",
    "    # Upsample minority class\n",
    "    df_minority_upsampled = resample(df_minority, \n",
    "                                     replace=True,     # sample with replacement\n",
    "                                     n_samples=n_samples, # number of samples we want for minority variable\n",
    "                                     random_state=123) # reproducible results\n",
    "\n",
    "    # Combine majority values with upsampled minority df\n",
    "    df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "    # Display new class counts\n",
    "    print(\"\\nTarget value counts after upsampling: \\n\" , df_upsampled.target.value_counts())\n",
    "    \n",
    "    \n",
    "    return df_upsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the dataset from train.CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train(1).csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.\tWrite at least 3 important inferences from the data above "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "•\tTarget column is imbalanced\n",
    "\n",
    "•\t4 types of columns\n",
    "\n",
    "•\tOutliers\n",
    "\n",
    "•\tNull values\n",
    "\n",
    "•\t6 variables have too low variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"• The dataset has \" + str(train.shape[0]) + \" rows and \" + str(train.shape[1]) + \" columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MetaData DataFrame for Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Metadata DataFrame so that it will be easy to handle and manipulate data during data exploration steps\n",
    "\n",
    "#role: input, ID, target\n",
    "#level: nominal, interval, ordinal, binary\n",
    "#keep: True or False\n",
    "#dtype: int, float, str\n",
    "\n",
    "MetaData = pd.DataFrame(columns=['variable','role', 'level', 'keep', 'dtype'])\n",
    "data =[]\n",
    "for columns in train.columns:\n",
    "    \n",
    "    #Defining Role\n",
    "    \n",
    "    if columns == 'id':\n",
    "        role = 'id'\n",
    "    elif columns == 'target':\n",
    "        role = 'target'\n",
    "    else:\n",
    "        role = 'input'\n",
    "        \n",
    "    #Defining DataTypes\n",
    "    \n",
    "    dtype = train[columns].dtype\n",
    "    \n",
    "    #Defining keep\n",
    "    \n",
    "    keep = True\n",
    "    \n",
    "    #Defining Level\n",
    "    \n",
    "    if columns[-3:] == 'bin' or columns == 'target':\n",
    "        level = 'binary'\n",
    "    elif columns[-3:] == 'cat' or columns == 'id':\n",
    "        level = 'categorical' \n",
    "    elif train[columns].dtype == float:\n",
    "        level = 'interval'\n",
    "    elif train[columns].dtype == np.int64:\n",
    "        level = 'ordinal'\n",
    "        \n",
    "        \n",
    "    f_dict = {\n",
    "        'variable' : columns,\n",
    "        'role': role,\n",
    "        'level': level,\n",
    "        'keep': keep,\n",
    "        'dtype': dtype\n",
    "    }\n",
    "    \n",
    "    data.append(f_dict)\n",
    "\n",
    "MetaData = MetaData.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.\tIs the data balanced? Meaning are targets 0 and 1 in the right proportion? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count of target variable.\n",
    "\n",
    "sns.countplot(train.target)\n",
    "train.groupby('target')['target'].count()"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)\n",
    "\n",
    "Data is highly imbalance with only ~3% of data belongs to minority (which is 1 in target) class. Need to do upscaling/down sampling after train-test split of data to get the desired results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the Distribution of variables across levels\n",
    "\n",
    "MetaData.groupby('level')[['variable']].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.\tHow many categorical features are there? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15 Categorical features are there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.\tHow many binary features are there? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18 Binary features are there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = null_value_check(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.\tWhich are the top two features in terms of missing values? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ps_car_03_cat, ps_car_05_cat have high percentage of missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.\tIn total, how many features have missing values? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total, there are 12 variables with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MetaData.loc[MetaData['variable'] == 'ps_car_03_cat', 'keep'] = False\n",
    "MetaData.loc[MetaData['variable'] == 'ps_car_05_cat', 'keep'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing variables that has high missing value count i.e ps_car_03_cat and ps_car_05_cat\n",
    "\n",
    "train1 = train.drop(['ps_car_03_cat', 'ps_car_05_cat'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_to_drop = ['ps_car_03_cat', 'ps_car_05_cat']\n",
    "\n",
    "# Imputing with the mean for non categorical variables\n",
    "\n",
    "mean_imp = SimpleImputer(missing_values=-1, strategy='mean')\n",
    "mode_imp = SimpleImputer(missing_values=-1, strategy='most_frequent')\n",
    "train1['ps_reg_03'] = mean_imp.fit_transform(train1[['ps_reg_03']]).ravel()\n",
    "train1['ps_car_12'] = mode_imp.fit_transform(train1[['ps_car_12']]).ravel()\n",
    "train1['ps_car_14'] = mean_imp.fit_transform(train1[['ps_car_14']]).ravel()\n",
    "train1['ps_car_11'] = mode_imp.fit_transform(train1[['ps_car_11']]).ravel()\n",
    "\n",
    "#Imputing missing values in categorical variables by their Mode\n",
    "\n",
    "filtered_missing = [ i for i in missing if not i in vars_to_drop]\n",
    "\n",
    "for columns in filtered_missing:\n",
    "    train1.loc[train1[columns] == -1, columns] = train1[columns].mode()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.\tWhat steps should be taken to handle the missing data? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can remove variable ps_car_03_cat, ps_car_05_cat as they have high percentage of missing values. For other variables, we can do missing value treatment by substituting mean and mode.\n",
    "Missing values in Categorical variables can be replaced by the mode value in that variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking missing values in the data, if any.\n",
    "null_value_check(train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of before null values check: \", train.shape)\n",
    "print('\\nShape of after null values check: ', train1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Correlation between different types of variables\n",
    "#Creating list of interval, categorical, binary and ordinal variables\n",
    "\n",
    "for variable in MetaData.variable:\n",
    "    IntervalVar = MetaData[MetaData.level=='interval']['variable']\n",
    "    CategoricalVar = MetaData[MetaData.level=='categorical']['variable']\n",
    "    BinaryVar = MetaData[MetaData.level=='binary']['variable']\n",
    "    OrdinalVar = MetaData[MetaData.level=='ordinal']['variable']\n",
    "    \n",
    "all_variables = [IntervalVar, CategoricalVar, BinaryVar, OrdinalVar]\n",
    "\n",
    "for x in all_variables:\n",
    "    fig, ax = plt.subplots(figsize=(20,10))\n",
    "    sns.heatmap(train[x].corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.\tWhich interval variables have strong correlation? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interval Variables: We can see the following variables are highly correlated \n",
    "ps_reg_01\n",
    "ps_reg_02\n",
    "ps_reg_03\n",
    "ps_reg_12\n",
    "ps_reg_13\n",
    "ps_reg_15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.\tWhat's the level of correlation among ordinal features? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordinal Variables: Very few are correlated to each other(negligible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now working for correlation in \"IND\"\n",
    "\n",
    "ind_col = [w for w in train1.columns if 'ind' in w]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,10))  \n",
    "sns.heatmap(train1[ind_col].corr(), annot= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PS_ind_06_bin and PS_ind_07_bin high correlation - so we drop PS_ind_06_bin\n",
    "# ps_ind_16_bin corr with ps_ind_17_bin and ps_ind_18_bin so we drop ps_ind_16_bin\n",
    "train2 = train1.drop([\"ps_ind_06_bin\", \"ps_ind_16_bin\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking correlation of 'car' variables\n",
    "car_col = [w for w in train2.columns if 'car' in w]\n",
    "fig, ax = plt.subplots(figsize=(15,10))  \n",
    "sns.heatmap(train2[car_col].corr() > 0.5, annot= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Droping variable 'ps_car_15' as it is highly correlated with the variable 'ps_car_13' and checking the shape of resulting\n",
    "#dataframe\n",
    "\n",
    "train3 = train2.drop([\"ps_car_15\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing calculated variables since there correlation with target variable is non significant\n",
    "\n",
    "column_excluding_calc  = [w for w in train3.columns if \"calc\" not in w]\n",
    "train4 = train3[column_excluding_calc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking correlation of \"REG\" variables\n",
    "\n",
    "reg_col = [w for w in train4.columns if 'reg' in w]\n",
    "fig, ax = plt.subplots(figsize=(8,5))  \n",
    "sns.heatmap(train4[reg_col].corr(), annot= True)\n",
    "\n",
    "#Reg variable seems to somewhat related\n",
    "#Creating interaction variables for 'reg' variables since they are highly correlated\n",
    "#Taking sum of ps_reg_01,ps_reg_03 and ps_reg_02\n",
    "#Droping variables 'ps_reg_01 and ps_reg02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of columns before correlation check: \", train1.shape[1])\n",
    "print('\\nNumber of columns after correlation check: ', train4.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers  = detect_outlier(train4.drop(['id', 'target'], axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing outliers from the dataframe\n",
    "\n",
    "train5 = train4.drop(train4.index[list(outliers)]).reset_index(drop = True)\n",
    "\n",
    "print('Number of outliers in more than one feature: {}'.format(len(outliers)))\n",
    "print('Shape of old data: {}'.format(train4.shape))\n",
    "print('Shape of new data: {}'.format(train5.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing low variance variables from the dataframe\n",
    "\n",
    "#Checking the number of low variance variables in the data using VarianceThreshold from sklearn feature_selection \n",
    "\n",
    "\n",
    "selector = VarianceThreshold(threshold=.01)\n",
    "selector.fit(train5.drop(['id', 'target'], axis=1)) # Fit to train without id and target variables\n",
    "\n",
    "f = np.vectorize(lambda x : not x) # Function to toggle boolean array elements\n",
    "\n",
    "v = train5.drop(['id', 'target'], axis=1).columns[f(selector.get_support())]\n",
    "print('{} variables have too low variance.'.format(len(v)))\n",
    "print('\\nThese variables are {}'.format(list(v)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the low variance variables from the data and checking the shape of the final dataframe\n",
    "\n",
    "train6 = train5.drop(list(v), axis = 1)\n",
    "print('\\nShape of df before removal of low variance rows: ',train5.shape)\n",
    "print('Shape of df after removal of low variance rows: ',train6.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating interaction variables for 'reg' variables since they are highly correlated\n",
    "#Taking sum of reg variable\n",
    "\n",
    "train6[\"sum_reg\"] = train6[\"ps_reg_01\"] + train6[\"ps_reg_02\"] + train6[\"ps_reg_03\"]\n",
    "\n",
    "#Droping variables 'ps_reg_01 and ps_reg02\n",
    "\n",
    "train7 = train6.drop([\"ps_reg_01\", \"ps_reg_02\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.\tWrite inferences from data on interval variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "•\tVariable “ps_reg_03” has 107772 missing values with 18.106490 percentage.\n",
    "\n",
    "•\tWe can see some of the variables are highly correlated like - ps_reg_01, ps_reg_02, ps_reg_03\n",
    "\n",
    "•\t“ps_car_12” has very low variance.\n",
    "\n",
    "•\tFeatures ps_reg_02, ps_reg_03, ps_car_12, ps_car_13, ps_car_14 and ps_car_15 have outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.\tWrite inferences from data on ordinal variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "•\tNo null values in ordinal variables.\n",
    "\n",
    "•\tVery few are correlated to each other(negligible)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.\tWrite inferences from data on binary variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "•\t“ps_ind_10_bin”, “ps_ind_11_bin”, “ps_ind_12_bin”, “ps_ind_13_bin” have very low variance.\n",
    "\n",
    "•\t“ps_ind_06_bin” and “ps_ind_07_bin” are significantly correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handling Categorical Variables\n",
    "#Creating dummy variables using get_dummies\n",
    "\n",
    "#Creating list of categorical variables\n",
    "\n",
    "cat_feat = MetaData[(MetaData.level == 'categorical') & (MetaData.keep == True)].variable\n",
    "\n",
    "#Creating dummy variables of categorical variables except variable - ps_car_11_cat as it conatins more than 100 categories\n",
    "\n",
    "v = MetaData[(MetaData.level == 'categorical') & (MetaData.keep)].variable\n",
    "v = [w for w in list(v) if w!='id' and w!='ps_car_11_cat']\n",
    "\n",
    "#Printing number of variables before and after dummification\n",
    "\n",
    "print('Before dummification we have {} variables in train'.format(train7.shape[1]))\n",
    "train8 = pd.get_dummies(train4, columns=v, drop_first=True)\n",
    "print('After dummification we have {} variables in train'.format(train8.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Implement Hot Encoding for categorical features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(train8.drop(['target', 'id'], axis=1),\n",
    "                                                    train8['target'].astype(int), \n",
    "                                                    test_size=0.30, \n",
    "                                                    random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_temp = X_train\n",
    "df_train_temp['target'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_temp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.\tWhat should be the preferred way in this case to balance the data? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to do upscaling/down sampling after train-test split of data to get the desired results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampled = up_and_down_sampling(df_train_temp,20)\n",
    "X_train_res = df_sampled.drop('target', axis = 1)\n",
    "y_train_res = df_sampled.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sampled = up_and_down_sampling(df_train_temp,12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.\tHow many training records are there after achieving a balance of 12%? "
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain a balance between majority and minority class, we used sampling techniques. After sampling there are there are 416648 rows in which 3,66,650 are 0s and 49,997 are 1s\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mms = StandardScaler()\n",
    "X_train_res_scaled = mms.fit_transform(X_train_res)\n",
    "#y_train_res_scaled = mms.fit_transform(y_train_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17.\tIn nominal(categorical) and interval features, which features are suitable for StandardScaler? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write the answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LogisticRegression()\n",
    "logistic_model = lm.fit(X_train_res, y_train_res)\n",
    "predictions_LM = logistic_model.predict(X_test)\n",
    "print(' Classification Report of Logistic Regression is: \\n')\n",
    "CR_LM = classification_report(y_test,predictions_LM) \n",
    "print(CR_LM)\n",
    "\n",
    "print('Confusion Matrix Logistic Regression is : \\n')\n",
    "print(confusion_matrix(y_test,predictions_LM))\n",
    "print(f1_score(y_test, predictions_LM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.\tThe Simple Logistic Regression Model seems to have high accuracy. Is that what we need at all? What is the problem with this model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Logistic Regression Model seems to high accuracy but Logistic regression is a linear model, so it may not work well on non-linear cases. In terms of model complexity, logistic regression has high bias and low variance. So, it might work well if you handle the outliers well but after model deployment, we cannot rely on the predictions because of the high bias and low variance characteristics of Logistic Regression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.\tWhy do you think f1-score is 0.0?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_RF = RandomForestClassifier(n_estimators=25, class_weight=\"balanced\")\n",
    "clf_RF.fit(X_train_res,y_train_res)\n",
    "predictions_RF = clf_RF.predict(X_test)\n",
    "\n",
    "print(' Classification Report of RandomForest Classifier is: \\n')\n",
    "CR_RF = classification_report(y_test,predictions_RF) \n",
    "print(CR_RF)\n",
    "\n",
    "print('Confusion matrix of RandomForest Classifier is: \\n')\n",
    "print(confusion_matrix(y_test,predictions_RF))\n",
    "print(f1_score(y_test, predictions_RF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.\tWhat is the precision and recall score for the model?"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have opted for Random Forest Classifier. So, the precision and recall score for my model are\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.\tWhat is the most important inference you can draw from the result?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write the answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.\tWhy do you think f1-score has improved?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write the answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Support Vector Classifier - (dual = True and max_iter = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_LSVC_1 = LinearSVC(dual = True , max_iter = 500)\n",
    "clf_LSVC_1.fit(X_train_res , y_train_res)\n",
    "predictions_LSVC_1 = clf_LSVC_1.predict(X_test)\n",
    "\n",
    "print(' Classification Report of  Linear Support Vector Classifier is: \\n')\n",
    "CR_LSVC_1 = classification_report(y_test,predictions_LSVC_1) \n",
    "print(CR_LSVC_1)\n",
    "\n",
    "print('Confusion Matrix Linear Support Vector Classifier is: \\n')\n",
    "print(confusion_matrix(y_test,predictions_LSVC_1))\n",
    "print(f1_score(y_test,predictions_LSVC_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Support Vector Classifier - (dual = False and max_iter = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_LSVC_2 = LinearSVC(dual = False , max_iter = 2000)\n",
    "clf_LSVC_2.fit(X_train_res , y_train_res)\n",
    "predictions_LSVC_2 = clf_LSVC_2.predict(X_test)\n",
    "\n",
    "print(' Classification Report of  RandomForest Classifier is: \\n')\n",
    "CR_LSVC_2 = classification_report(y_test,predictions_LSVC_2) \n",
    "print(CR_LSVC_2)\n",
    "\n",
    "print('Confusion Matrix Linear Support Vector Classifier is: \\n')\n",
    "print(confusion_matrix(y_test,predictions_LSVC_2))\n",
    "print(f1_score(y_test,predictions_LSVC_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.\tFor model LinearSVC play with parameters – dual, max_iter and see if there is any improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Didn’t find any improvement after tweaking the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM with Only 100k records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train8.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train9 = train8[:100000]\n",
    "train9.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train9.drop(['target', 'id'], axis=1),\n",
    "                                                    train9['target'].astype(int), \n",
    "                                                    test_size=0.30, \n",
    "                                                    random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_temp = X_train\n",
    "df_train_temp['target'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train9['target'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upsampling and downsampling\n",
    "df_upsampled_SVM = up_and_down_sampling(train6, 20)\n",
    "X_train_res_SVM = df_upsampled_SVM.drop('target', axis = 1)\n",
    "y_train_res_SVM = df_upsampled_SVM.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf_SVC = svm.SVC()\n",
    "clf_SVC.fit(X_train_res_SVM , y_train_res_SVM)\n",
    "predictions_SVC = clf_SVC.predict(X_test)\n",
    "\n",
    "print(' Classification Report of  SVC with only 100k records is: \\n')\n",
    "CR_XGB = classification_report(y_test,predictions_SVC) \n",
    "print(CR_XGB)\n",
    "\n",
    "print('Confusion Matrix SVC with only 100k records is: \\n')\n",
    "print(confusion_matrix(y_test,predictions_SVC))\n",
    "print(f1_score(y_test,predictions_SVC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.\tSVC with Imbalance Check & Feature Optimization & only 100K Records → is there improvement in scores?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision and recall scores for the target value ‘1’ became zero which implies the recall of the model is not good. This might because of the huge difference between the number of 0’s and 1’s in the target column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_XGB = XGBClassifier()\n",
    "clf_XGB.fit(X_train_res , y_train_res)\n",
    "predictions_XGB = clf_XGB.predict(X_test)\n",
    "\n",
    "print(' Classification Report of  XGBClassifier is: \\n')\n",
    "CR_XGB = classification_report(y_test,predictions_XGB) \n",
    "print(CR_XGB)\n",
    "\n",
    "print('Confusion Matrix XGBClassifier is: \\n')\n",
    "print(confusion_matrix(y_test,predictions_XGB))\n",
    "print(f1_score(y_test,predictions_XGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. XGBoost is one the better classifiers -- but still f1-score is very low. What could be the reason? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1-score is not low for my model. Instead Gradient Boosting gives low f1-scores \n",
    "\n",
    "•\tOverfitting \n",
    "\n",
    "•\tImproper Hyperparameter tuning\n",
    "\n",
    "Gradient Boosting trees build one tree at a time and each newly added tree helps to correct errors made by previously trained tree. There are typically three parameters – number of trees, depth of tree and learning rate. Gradient boosting trees are more prone to overfitting since it requires a lot of hyperparameter tuning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run xgb for df which doesnt have get dummies or one hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.\tWhat is the increase in number of features after one-hot encoding of the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The increase in the features is "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.\tIs there any improvement in scores after encoding?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write the answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.\tIf not missing a positive sample is the priority which model is best so far? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write the answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.\tIf not marking negative sample as positive is top priority, which model is best so far? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run adaboost and show the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.\tDo you think using AdaBoost can give any significant improvement over XGBoost? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There will be a significant improvement but XG boost performs better than Adaboost in most of the cases as it can handle large amounts of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Layer Perceptron Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#Training the MLP classifier with only 100k records since training the model with full dataset requires high computational power\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf_MLP = MLPClassifier()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from sklearn.model_selection import GridSearchCV\n",
    "hidden_layer_sizes = [[20] , [40,20] , [40,20,10]]\n",
    "activation = ['logistic' , 'relu']\n",
    "param_grid = dict(hidden_layer_sizes = hidden_layer_sizes , activation  = activation , batch_size = [10000,15000])\n",
    "grid = GridSearchCV(estimator = clf_MLP , param_grid = param_grid)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''grid_result = grid.fit(X_train,y_train)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''grid_result.best_score_,grid_result.best_params_'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.\tMLPClassifier is the neural network we are trying. But how to choose the right no. of layers and size? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use GridSearchCV, RandomizedSearchCV ,etc.. to find the best parameters for the MLP classifier. But if the dataset is large, it takes a lot of time (if you have less computational power) to get the best parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.\tAt what layer size we get the best f1-score?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At one hidden layer with a size of 20 neurons , I got the best f1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
